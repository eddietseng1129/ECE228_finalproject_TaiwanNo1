{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "SIZE = 128\n",
    "\n",
    "# load file\n",
    "train_images = glob.glob(\"whaleIdentification/train/*jpg\")\n",
    "test_images = glob.glob(\"whaleIdentification/test/*jpg\")\n",
    "df = pd.read_csv(\"whaleIdentification/train.csv\")\n",
    "\n",
    "df[\"Image\"] = df[\"Image\"].map( lambda x : \"whaleIdentification/train/\"+x)\n",
    "ImageToLabelDict = dict( zip( df[\"Image\"], df[\"Id\"]))\n",
    "\n",
    "#image are imported with a resizing and a black and white conversion\n",
    "def ImportImage(filename):\n",
    "    img = Image.open(filename).convert(\"RGB\").resize((SIZE,SIZE)) #.convert(\"LA\")\n",
    "    return np.array(img)[:,:,:]\n",
    "\n",
    "# transfer label to one-hot\n",
    "class LabelOneHotEncoder():\n",
    "    def __init__(self):\n",
    "        self.ohe = OneHotEncoder()\n",
    "        self.le = LabelEncoder()\n",
    "    def fit_transform(self, x):\n",
    "        features = self.le.fit_transform(x)\n",
    "        return self.ohe.fit_transform(features.reshape(-1,1))\n",
    "    def transform(self, x):\n",
    "        return self.ohe.transform(self.la.transform(x.reshape(-1,1)))\n",
    "    def inverse_tranform( self, x):\n",
    "        return self.le.inverse_transform(self.ohe.inverse_tranform(x))\n",
    "    def inverse_labels(self, x):\n",
    "        return self.le.inverse_transform(x)\n",
    "\n",
    "# transfer label to one-hot\n",
    "y = list(map(ImageToLabelDict.get, train_images))\n",
    "lohe = LabelOneHotEncoder()\n",
    "y_cat = lohe.fit_transform(y)\n",
    "print (y_cat.shape)\n",
    "\n",
    "# constructing class weights\n",
    "# due to imbalanced dataset\n",
    "WeightFunction = lambda x : 1./x**0.75\n",
    "ClassLabel2Index = lambda x : lohe.le.inverse_tranform([[x]])\n",
    "CountDict = dict(df[\"Id\"].value_counts())\n",
    "class_weight_dic = {lohe.le.transform([image_name])[0] : WeightFunction(count) for image_name, count in CountDict.items()}\n",
    "del CountDict\n",
    "\n",
    "#use of an image generator for preprocessing and data augmentation\n",
    "x = x.reshape((-1,SIZE,SIZE,3))\n",
    "input_shape = x[0].shape\n",
    "x_train = x.astype(\"float32\")\n",
    "y_train = y_cat\n",
    "\n",
    "image_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "#training the image preprocessing\n",
    "image_gen.fit(x_train, augment=True)\n",
    "\n",
    "# transfer learning requries RGB\n",
    "x_train_3 = x.reshape((-1,SIZE,SIZE,3))\n",
    "x_train_3 = x_train_3.astype(\"float32\")\n",
    "\n",
    "\n",
    "# ========== transfer learning ==========\n",
    "\n",
    "# building model\n",
    "batch_size = 128\n",
    "num_classes = len(y_cat.toarray()[0])\n",
    "epochs = 100\n",
    "\n",
    "# model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (SIZE, SIZE, 3))\n",
    "\n",
    "model = applications.InceptionResNetV2(weights = None, include_top=False, input_shape = (SIZE, SIZE, 3))\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing all layers due to small dataset.\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "#Now we will be training only the classifiers (FC layers)\n",
    "\n",
    "#Adding custom Layers \n",
    "x_model = model.output\n",
    "x_model = Flatten()(x_model)\n",
    "x_model = Dense(2048, activation=\"relu\")(x_model)\n",
    "x_model = Dropout(0.5)(x_model)\n",
    "x_model = Dense(2048, activation=\"relu\")(x_model)\n",
    "predictions = Dense(4251, activation=\"softmax\")(x_model)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(inputs = model.input, outputs = predictions)\n",
    "\n",
    "# load previous training model\n",
    "model_final.load_weights(\"IncepResV2_3.h5\")\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adadelta(), metrics=[\"accuracy\"])\n",
    "\n",
    "#training the image preprocessing\n",
    "train_datagen = image_gen.fit(x_train_3, augment=True)\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "# checkpoint = ModelCheckpoint(\"vgg19_1.h5\", monitor='val_acc', verbose=1, save_weights_only=False, mode='auto', period=1) #, save_best_only=True\n",
    "checkpoint = ModelCheckpoint(\"IncepResV2_3.h5\", monitor='val_acc', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "# Train the model \n",
    "with tf.device('/gpu:0'):\n",
    "    model_final.fit_generator(\n",
    "    image_gen.flow(x_train_3, y_train.toarray(), batch_size=batch_size),\n",
    "    steps_per_epoch = x_train_3.shape[0]//batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = [checkpoint, early])\n",
    "\n",
    "\n",
    "# total training accuracy \n",
    "score_3 = model_final.evaluate(x_train_3, y_train, verbose=0)\n",
    "print('Training loss: {0:.4f}\\nTraining accuracy:  {1:.4f}'.format(*score_3))\n",
    "\n",
    "# output of testing images (prediction) \n",
    "import warnings\n",
    "from os.path import split\n",
    "\n",
    "with open(\"transfer_submission.csv\",\"w\") as f:\n",
    "    with warnings.catch_warnings():\n",
    "        f.write(\"Image,Id\\n\")\n",
    "        warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "        for image in test_images:\n",
    "            img = ImportImage( image)\n",
    "            x = img.astype( \"float32\")\n",
    "            #applying preprocessing to test images\n",
    "            x = image_gen.standardize( x.reshape(1,SIZE,SIZE,3))\n",
    "            y = model_final.predict_proba(x.reshape(1,SIZE,SIZE,3))\n",
    "            predicted_args = np.argsort(y)[0][::-1][:5]\n",
    "            predicted_tags = lohe.inverse_labels( predicted_args)\n",
    "            image = split(image)[-1]\n",
    "            predicted_tags = \" \".join( predicted_tags)\n",
    "            f.write(\"%s,%s\\n\" %(image, predicted_tags))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
